{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " # Predicting High Healthcare Costs: Risk Modeling  \n",
        "## Notebook 2 • Predictive Modeling\n",
        "\n",
        "**Goal:**  \n",
        "Build a classification model that predicts which members are likely to incur high annual medical charges (> $20,000) using only demographic and behavioral characteristics.\n",
        "\n",
        "### Why This Matters\n",
        "A small portion of members often drive a large share of total healthcare costs.  \n",
        "Health plans can use predictive analytics to:\n",
        "- Identify rising-risk members early  \n",
        "- Support care management and preventive interventions  \n",
        "- Improve budgeting and actuarial forecasts  \n",
        "- Allocate resources more efficiently\n",
        "\n",
        "### Modeling Approach  \n",
        "This notebook evaluates two supervised classification models:\n",
        "\n",
        "1. **Logistic Regression**  \n",
        "   - Interpretable, fast, and effective.\n",
        "   - Recommended when explainability matters.\n",
        "\n",
        "2. **Random Forest**  \n",
        "   - Nonlinear, handles interactions well.  \n",
        "   - Recommended when prediction performance is prioritized.\n",
        "\n",
        "Both models are trained and compared based on:\n",
        "- ROC-AUC  \n",
        "- Recall, Precision, F1  \n",
        "- Real-world implications\n"
      ],
      "metadata": {
        "id": "_iipnh9q4RMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Author:** Ivy Maina"
      ],
      "metadata": {
        "id": "_-6rEZ9bG2Q2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rndV6StD3ePJ"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "df = pd.read_csv('/content/medical_insurance_costs.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#High-Cost Label Distribution\n",
        "#Rule: Chargers higher than $20,000 are high cost.\n",
        "\n",
        "df['high_cost'] = np.where(df['charges'] > 20000, 1, 0)\n",
        "df['high_cost'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "b7M-Gwuh47FE",
        "outputId": "5df1b067-1fd6-4dd3-ad4f-4e3f18da4faf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "high_cost\n",
              "0    1065\n",
              "1     273\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high_cost</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**High-Cost Label Distribution**\n",
        "\n",
        "To prepare for modeling, members were labeled as high cost if their annual medical charges exceeded $20,000.\n",
        "\n",
        "**High-cost population breakdown**\n",
        "- **273 members (20%)** fall into the high-cost category.  \n",
        "- **1,065 members (80%)** are in the low/normal cost group.\n",
        "\n",
        "This imbalance is common in healthcare claims where a small share of members often drives a large share of total cost. It also means we’ll need to pay extra attention to metrics like recall and ROC-AUC, not just accuracy.\n"
      ],
      "metadata": {
        "id": "IHe76AW15rq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose features + Target\n",
        "X = df[['age','sex','bmi','children','smoker','region']]\n",
        "y = df['high_cost']\n"
      ],
      "metadata": {
        "id": "MBBULMQ96PZL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature & Target Selection**\n",
        "\n",
        "To train a predictive model, we split the dataset into:\n",
        "- **Input features (X):**  \n",
        "  `age`, `sex`, `bmi`, `children`, `smoker`, `region`  \n",
        "  These represent demographic and lifestyle factors that may influence healthcare spending.\n",
        "  \n",
        "- **Target variable (y):**  \n",
        "  `high_cost` — a binary label indicating whether a member incurred **> $20,000** in charges.\n",
        "\n",
        "By selecting only member-level factors (rather than charges), we ensure the model learns to predict high spenders using information available before medical expenses occur."
      ],
      "metadata": {
        "id": "9Fb96nQu6css"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train-test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "Kk1-ZCiU6xIf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train–Test Split**\n",
        "\n",
        "To evaluate how well our model generalizes to unseen members, the dataset was split into:\n",
        "\n",
        "- **Training set:** 80% of observations.  \n",
        "- **Test set:** 20% of observations.  \n",
        "- **Stratified sampling:** ensures the high-cost class (20%) is represented proportionally in both sets.\n",
        "\n",
        "Stratifying is critical in healthcare risk modeling because without it, the minority high-cost population might be under-represented in the train or test set, leading to biased and unreliable predictions."
      ],
      "metadata": {
        "id": "iCmMR7sl66m7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess categorical + numeric\n",
        "\n",
        "numeric = ['age','bmi','children']\n",
        "categorical = ['sex','smoker','region']\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric),\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "paRHDigM7SNe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**\n",
        "\n",
        "Before training any models, we prepare the features using a ColumnTransformer:\n",
        "\n",
        "**Numeric features** (`age`, `bmi`, `children`)  \n",
        "- Scaled using StandardScaler to normalize ranges.  \n",
        "- Helps algorithms (especially Logistic Regression) converge more reliably.\n",
        "\n",
        "**Categorical features** (`sex`, `smoker`, `region`)  \n",
        "- Converted into numerical form using OneHotEncoder.\n",
        "- First category dropped to avoid multicollinearity (“dummy trap”).\n",
        "\n",
        "This preprocessing pipeline ensures that both numeric and categorical inputs are handled correctly and consistently across training and evaluation. This is critical for fair and interpretable healthcare models.\n"
      ],
      "metadata": {
        "id": "bKmfNI3S_jVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression Model\n",
        "\n",
        "logreg = Pipeline(steps=[\n",
        "    ('prep', preprocess),\n",
        "    ('model', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "pred_lr = logreg.predict(X_test)\n",
        "proba_lr = logreg.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, proba_lr))\n",
        "print(classification_report(y_test, pred_lr))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcWggQtS7Yi6",
        "outputId": "ac283a99-f588-46ef-80d4-ed614db0cef0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC: 0.9508322663252241\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       213\n",
            "           1       0.85      0.85      0.85        55\n",
            "\n",
            "    accuracy                           0.94       268\n",
            "   macro avg       0.91      0.91      0.91       268\n",
            "weighted avg       0.94      0.94      0.94       268\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**\n",
        "\n",
        "The Logistic Regression model performs strongly at predicting high-cost members.\n",
        "\n",
        "**Evaluation Metrics**\n",
        "- **ROC-AUC:** 0.95\n",
        "\n",
        "This indicates excellent ability to distinguish between high-cost and low-cost groups\n",
        "\n",
        "**Classification Performance**\n",
        "| Metric | High Cost (1) | Low Cost (0) |\n",
        "|--------|----------------|---------------|\n",
        "| Precision | 0.85 | 0.96 |\n",
        "| Recall    | 0.85 | 0.96 |\n",
        "| F1-score  | 0.85 | 0.96 |\n",
        "\n",
        "**Overall Accuracy:** 94%\n",
        "\n",
        "**Key takeaway:**\n",
        "\n",
        "The model correctly identifies 85% of high-cost members, which is a strong recall score for healthcare risk prediction, where missing high-cost patients can lead to major spend surprises.  \n",
        "\n",
        "This suggests that Logistic Regression is already capturing meaningful signals from member demographics and lifestyle factors.\n"
      ],
      "metadata": {
        "id": "JhZUeFv5AJon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Model\n",
        "\n",
        "rf = Pipeline(steps=[\n",
        "    ('prep', preprocess),\n",
        "    ('model', RandomForestClassifier(n_estimators=300, random_state=42))\n",
        "])\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "pred_rf = rf.predict(X_test)\n",
        "proba_rf = rf.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, proba_rf))\n",
        "print(classification_report(y_test, pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peqpIdH0_Ooh",
        "outputId": "87ab380b-93ad-43b1-8a01-6c3999d32cd7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC: 0.9200597524541186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       213\n",
            "           1       1.00      0.82      0.90        55\n",
            "\n",
            "    accuracy                           0.96       268\n",
            "   macro avg       0.98      0.91      0.94       268\n",
            "weighted avg       0.96      0.96      0.96       268\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**\n",
        "\n",
        "The Random Forest model delivers excellent performance with strong balance between catching high-cost members and minimizing false alarms.\n",
        "\n",
        "**Evaluation Metrics**\n",
        "- **ROC-AUC:** 0.92  \n",
        "Slightly lower than Logistic Regression, but still very strong signal separation.\n",
        "\n",
        "**Classification Performance**\n",
        "| Metric | High Cost (1) | Low Cost (0) |\n",
        "|--------|----------------|---------------|\n",
        "| Precision | **1.00** | 0.96 |\n",
        "| Recall    | 0.82 | **1.00** |\n",
        "| F1-score  | 0.90 | 0.98 |\n",
        "\n",
        "**Overall Accuracy:** 96%\n",
        "\n",
        "**Key takeaway:**  \n",
        "Random Forest identifies all predicted high-cost members correctly (precision = 100%), meaning it rarely misclassifies someone as high-cost when they are not.  \n",
        "However, it misses a few true high-cost members (82% recall), suggesting a mild risk of underestimating cost impact.\n",
        "\n",
        "This makes Random Forest appealing for use cases where false positives are costly, while Logistic Regression may be stronger where capturing every high-cost member is critical.\n"
      ],
      "metadata": {
        "id": "zSZu4WPoA21z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Importance (RF)\n",
        "\n",
        "# Get encoded feature names\n",
        "ohe = rf.named_steps['prep'].named_transformers_['cat']\n",
        "feature_names = numeric + list(ohe.get_feature_names_out(categorical))\n",
        "\n",
        "importances = rf.named_steps['model'].feature_importances_\n",
        "\n",
        "fi = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': importances\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "fi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9Jq_l7N4_Vov",
        "outputId": "1e15f054-7c4c-495d-8795-ee4db3c56e44"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            feature  importance\n",
              "4        smoker_yes    0.473064\n",
              "1               bmi    0.242266\n",
              "0               age    0.174160\n",
              "2          children    0.054231\n",
              "3          sex_male    0.016979\n",
              "6  region_southeast    0.014482\n",
              "5  region_northwest    0.013353\n",
              "7  region_southwest    0.011464"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d91f79df-86ff-4e03-8068-76f4126a27e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>smoker_yes</td>\n",
              "      <td>0.473064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bmi</td>\n",
              "      <td>0.242266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>age</td>\n",
              "      <td>0.174160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>children</td>\n",
              "      <td>0.054231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sex_male</td>\n",
              "      <td>0.016979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>region_southeast</td>\n",
              "      <td>0.014482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>region_northwest</td>\n",
              "      <td>0.013353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>region_southwest</td>\n",
              "      <td>0.011464</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d91f79df-86ff-4e03-8068-76f4126a27e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d91f79df-86ff-4e03-8068-76f4126a27e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d91f79df-86ff-4e03-8068-76f4126a27e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_c9e59435-ac80-401b-83a4-a44af2a630c4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('fi')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c9e59435-ac80-401b-83a4-a44af2a630c4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('fi');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "fi",
              "summary": "{\n  \"name\": \"fi\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"bmi\",\n          \"region_southeast\",\n          \"smoker_yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16542728886302852,\n        \"min\": 0.011463888341144672,\n        \"max\": 0.47306439832520825,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.2422660486906286,\n          0.014481994936645854,\n          0.47306439832520825\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Importance - Random Forest**\n",
        "\n",
        "To understand what drives high medical spending, we examined feature importance scores from the Random Forest model.\n",
        "\n",
        "**Top Predictors of High Cost**\n",
        "1. **Smoker status** - 0.47 importance\n",
        "- Strongest signal by far.\n",
        "- Smoking alone accounts for nearly half the predictive power.  \n",
        "- Aligns with real-world risk where tobacco use leads to dramatically higher claims.\n",
        "\n",
        "2. **BMI** - 0.24 importance  \n",
        "- Higher BMI likely increases risk for chronic conditions, hospitalizations, and procedures\n",
        "\n",
        "3. **Age** - 0.17 importance\n",
        "- Costs naturally rise with age due to higher utilization, comorbidities, and preventive screenings.\n",
        "\n",
        "4. **Children** - 0.05 importance  \n",
        "- Minor impact, but may reflect additional covered dependents.\n",
        "\n",
        "5. **Sex & Region** — Less than 2% contribution each  \n",
        "- These variables matter less for predicting extreme cost in this dataset.\n",
        "\n",
        "**Key Insight:**  \n",
        "Lifestyle and physiological factors (**smoking + BMI**) are far more predictive of high-cost claims than geography or gender.\n",
        "\n",
        "This suggests health plans can:\n",
        "- Target smoking cessation programs\n",
        "- Flag obesity risk early\n",
        "- Predict high spenders using minimal demographic inputs\n"
      ],
      "metadata": {
        "id": "e2puA6ULBgSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Model Evaluation Summary**\n",
        "\n",
        "Both models performed exceptionally well in predicting whether a member will incur over $20,000 in annual medical charges, but each excels in a different way.\n",
        "\n",
        "**Logistic Regression**\n",
        "- ROC-AUC: 0.95  \n",
        "- Recall (High Cost): 0.85  \n",
        "- Precision (High Cost): 0.85  \n",
        "- Accuracy: 94%\n",
        "\n",
        "- Best for identifying as many high-cost members as possible. It is critical when the goal is early intervention.\n",
        "\n",
        "**Random Forest**\n",
        "- ROC-AUC: 0.92  \n",
        "- Recall (High Cost): 0.82  \n",
        "- Precision (High Cost): 1.00  \n",
        "- Accuracy: 96%\n",
        "\n",
        "- Best when false positives are costly — it rarely misclassifies a low-cost member as high-cost, but misses a few true high-cost members.*\n",
        "\n",
        "---\n",
        "\n",
        "**Key Predictors of High Medical Spending**\n",
        "\n",
        "Feature importance analysis confirms that:\n",
        "1. **Smoker status** (largest driver, nearly 50% of model signal)\n",
        "2. **BMI**\n",
        "3. **Age**\n",
        "\n",
        "Together, these three factors explain the majority of variation in high spending.\n",
        "\n",
        "---\n",
        "\n",
        "**Business Takeaways**\n",
        "\n",
        "- Smoking cessation and weight management programs could meaningfully reduce high claims.\n",
        "- Health plans can risk-stratify members using simple demographic fields, even before full claims history is available.\n",
        "- Predictive modeling supports proactive outreach, budgeting, and care management planning\n",
        "- Different model types support different operational use cases:\n",
        "  - Logistic Regression: maximize high-risk capture  \n",
        "  - Random Forest: minimize false alarms\n",
        "\n",
        "---\n",
        "\n",
        "**Final Conclusion**\n",
        "\n",
        "This modeling demonstrates that even a small number of member-level features can reliably predict high-cost individuals.  \n",
        "Such models can help payers, providers, and care management teams act earlier, enabling better health outcomes and more sustainable spending.\n"
      ],
      "metadata": {
        "id": "OldQy1eIC7Cw"
      }
    }
  ]
}